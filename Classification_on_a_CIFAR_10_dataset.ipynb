{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification on a CIFAR 10 dataset.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aayush97/GoogleColabPetProjects/blob/master/Classification_on_a_CIFAR_10_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnIsQjhIt2kg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from skimage import io, transform\n",
        "import pandas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYSB9-GoAV-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3,10,3,2) # 3 input channels RGB, 10 output channels, 3x3 kernel, valid convolution\n",
        "    self.d1 = nn.Dropout2d(p=.2)\n",
        "    self.conv2 = nn.Conv2d(10,20,5,2) # 10 input channels, 20 output channels, 5x5 kernel, stride=2\n",
        "    self.d2 = nn.Dropout2d(p=.2)\n",
        "    # 13x13x20\n",
        "    self.fc1 = nn.Linear(6*6*20, 120)\n",
        "    self.d3 = nn.Dropout(p=.5)\n",
        "    self.fc2 = nn.Linear(120,80)\n",
        "    self.fc3 = nn.Linear(80,10)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.d1(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.d2(x)\n",
        "    # reshape x\n",
        "    x=x.view(-1,self.num_flat_features(x))\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.d3(x)\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "  \n",
        "  def num_flat_features(self,x):\n",
        "    size = x.size()[1:]\n",
        "    retVal=1\n",
        "    for s in size:\n",
        "      retVal*=s\n",
        "    return retVal\n",
        "\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(Net, self).__init__()\n",
        "#         self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "#         self.pool = nn.MaxPool2d(2, 2)\n",
        "#         self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "#         self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "#         self.fc2 = nn.Linear(120, 84)\n",
        "#         self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.pool(F.relu(self.conv1(x)))\n",
        "#         x = self.pool(F.relu(self.conv2(x)))\n",
        "#         x = x.view(-1, 16 * 5 * 5)\n",
        "#         x = F.relu(self.fc1(x))\n",
        "#         x = F.relu(self.fc2(x))\n",
        "#         x = self.fc3(x)\n",
        "#         return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TylbLQOuI7GS",
        "colab_type": "code",
        "outputId": "67e7d897-dbd8-4e5c-f03e-9850ee78d053",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(2, 2))\n",
            "  (d1): Dropout2d(p=0.2)\n",
            "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(2, 2))\n",
            "  (d2): Dropout2d(p=0.2)\n",
            "  (fc1): Linear(in_features=720, out_features=120, bias=True)\n",
            "  (d3): Dropout(p=0.5)\n",
            "  (fc2): Linear(in_features=120, out_features=80, bias=True)\n",
            "  (fc3): Linear(in_features=80, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5oEIFc0I-bN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load_dataset #CIFAR 10\n",
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lhD-v1-MbD6",
        "colab_type": "code",
        "outputId": "2da00524-ac9a-42d7-aa2a-da87c89bfb42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW6H37RKMygt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = '/content/gdrive/My Drive/'\n",
        "x_train =  torch.tensor(1)\n",
        "y_train = torch.tensor(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8ateR7SYBT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get images from CIFAR dataset\n",
        "for i in range(5):  \n",
        "  dataset =  unpickle(PATH+'cifar-10-python/cifar-10-batches-py/data_batch_'+str(i+1))\n",
        "  datan = dataset[b'data']\n",
        "  labels = dataset[b'labels']\n",
        "  labels = torch.LongTensor(labels)\n",
        "  labels = labels.view(1,10000)\n",
        "  data = torch.from_numpy(datan)\n",
        "  data = data.view(1,10000,3,32,32)\n",
        "  data = data.float()\n",
        "  if(i==0):\n",
        "    x_train = data\n",
        "    y_train = labels\n",
        "  else:\n",
        "    x_train = torch.cat((x_train,data),0)\n",
        "    y_train = torch.cat((y_train,labels),0)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Vu1w1NSb1F2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#testing dataset\n",
        "dataset =  unpickle(PATH+'cifar-10-python/cifar-10-batches-py/test_batch')\n",
        "datan = dataset[b'data']\n",
        "labels = dataset[b'labels']\n",
        "labels = torch.LongTensor(labels)\n",
        "labels = labels.view(1,10000)\n",
        "data = torch.from_numpy(datan)\n",
        "data = data.view(1,10000,3,32,32)\n",
        "data=data.float()\n",
        "x_test = data\n",
        "y_test = labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK5ZCeAXCubc",
        "colab_type": "code",
        "outputId": "49688b1d-5443-48cf-ac11-33b67457f354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "import torch.optim as optim\n",
        "#Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "#training\n",
        "epochs = 30\n",
        "for epoch in range(epochs):\n",
        "  for i in range(5):\n",
        "    optimizer.zero_grad()   # zero the gradient buffers\n",
        "    output = net(x_train[i])\n",
        "    loss = criterion(output, y_train[i])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(loss)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.5682, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5103, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5142, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4811, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4565, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4592, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4639, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4529, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4449, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4435, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4307, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4352, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4213, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4195, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4293, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4151, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4259, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4325, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4152, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4091, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4021, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3982, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3876, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3930, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3902, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3822, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3798, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3812, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3849, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3922, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owlHRo5mTQR_",
        "colab_type": "code",
        "outputId": "4a0ecc80-27de-4b06-de90-6edacccaba0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#testing\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    output = net(x_test[0])\n",
        "    for i in range(output.shape[0]):\n",
        "      _,index = output[i].max(0)\n",
        "      if(y_test[0][i]==index):\n",
        "        correct+=1\n",
        "    total = output.shape[0]\n",
        "    \n",
        "print('Accuracy of the network on   the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on   the 10000 test images: 57 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lz7o7HCbBD7",
        "colab_type": "code",
        "outputId": "38df50a9-39e4-483f-881c-98cca50342e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "net.d1.eval()\n",
        "net.d2.eval()\n",
        "net.d3.eval()\n",
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(2, 2))\n",
            "  (d1): Dropout2d(p=0.2)\n",
            "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(2, 2))\n",
            "  (d2): Dropout2d(p=0.2)\n",
            "  (fc1): Linear(in_features=720, out_features=120, bias=True)\n",
            "  (d3): Dropout(p=0.5)\n",
            "  (fc2): Linear(in_features=120, out_features=80, bias=True)\n",
            "  (fc3): Linear(in_features=80, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIGa-IHIII5Q",
        "colab_type": "text"
      },
      "source": [
        "**Classify MNIST Handwritten digits using the same neural network architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ_oixcpITrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "import requests"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLso3k4FIV_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_PATH = Path(\"data\")\n",
        "PATH = DATA_PATH / \"mnist\"\n",
        "\n",
        "PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "URL = \"http://deeplearning.net/data/mnist/\"\n",
        "FILENAME = \"mnist.pkl.gz\"\n",
        "\n",
        "if not (PATH / FILENAME).exists():\n",
        "        content = requests.get(URL + FILENAME).content\n",
        "        (PATH / FILENAME).open(\"wb\").write(content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UT-0zXNIYj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import gzip\n",
        "\n",
        "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
        "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMrPAeDNIcxa",
        "colab_type": "code",
        "outputId": "8d1a45c7-c327-4f19-ef5e-b43bec3eb92f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "import torch\n",
        "x_train, y_train, x_valid, y_valid = map(\n",
        "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
        ")\n",
        "print (x_train.shape)\n",
        "x_train = x_train.view(-1,28,28)\n",
        "x_t = torch.zeros([50000,32,32])\n",
        "print(x_t.shape)\n",
        "x_t[:,:28,:28] = x_train\n",
        "x_train = x_t\n",
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "\n",
        "pyplot.imshow(x_train[0], cmap=\"gray\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([50000, 784])\n",
            "torch.Size([50000, 32, 32])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe4c82180b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF0nDUZLIgN-",
        "colab_type": "code",
        "outputId": "0439bdfa-8215-412a-bdc8-93b254a85072",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "\n",
        "print (x_valid.shape)\n",
        "x_valid = x_valid.view(-1,28,28)\n",
        "x_v = torch.zeros([10000,32,32])\n",
        "print(x_v.shape)\n",
        "x_v[:,:28,:28] = x_valid\n",
        "x_valid = x_v\n",
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "\n",
        "pyplot.imshow(x_valid[0], cmap=\"gray\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10000, 784])\n",
            "torch.Size([10000, 32, 32])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe4c8183978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKpThlwpl+KVCGX6pUP8LPDsedTNEQHcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8fkZgmAOD3B",
        "colab_type": "code",
        "outputId": "9f35a89c-d1be-4018-ce75-5d2ea62c0851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "class Net2(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(Net2,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1,6,5)\n",
        "    self.conv2 = nn.Conv2d(6,16,5)\n",
        "    self.fc1 = nn.Linear(16*5*5,120)\n",
        "    self.fc2 = nn.Linear(120,84)\n",
        "    self.fc3 = nn.Linear(84,10)\n",
        "    \n",
        "  def forward(self,x):\n",
        "    x = F.max_pool2d(F.relu(self.conv1(x)),2)\n",
        "    x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
        "    x = x.view(-1,self.num_flat_features(x))\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "    \n",
        "  def num_flat_features(self,x):\n",
        "    size = x.size()[1:]\n",
        "    num_features = 1\n",
        "    for s in size:\n",
        "      num_features *= s\n",
        "    return num_features\n",
        "net2 = Net2()\n",
        "print(net2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net2(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms968d-cOU82",
        "colab_type": "code",
        "outputId": "c68acd74-04a3-4457-9cbf-e0b16d63d70f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#train net2\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net2.parameters())\n",
        "#training\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "  for i in range(500):\n",
        "    optimizer.zero_grad()   # zero the gradient buffers\n",
        "    output = net2(x_train[i*100:(i+1)*100].view(100,1,32,32))\n",
        "    loss = criterion(output, y_train[i*100:(i+1)*100])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0514, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0196, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0280, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0568, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0483, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOVLY2y_PrKz",
        "colab_type": "code",
        "outputId": "774d40fb-0653-43f3-a223-b895b8f980e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#testing\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    output = net2(x_valid.view(-1,1,32,32))\n",
        "    for i in range(output.shape[0]):\n",
        "      _,index = output[i].max(0)\n",
        "      if(y_valid[i]==index):\n",
        "        correct+=1\n",
        "    total = output.shape[0]\n",
        "    \n",
        "print('Accuracy of the network on the', total ,'test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 98 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyIbdXT9TXzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}